{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "all_train_data = pd.read_csv('Dataset/TrainOnMe.csv', sep=',', na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['x1', 'x2', 'x3', 'x4', 'x7', 'x8', 'x9', 'x10']\n",
    "cat_cols = ['x5', 'x6']\n",
    "\n",
    "# data preprocessing function\n",
    "def data_prepocessing(df): \n",
    "    df = df.iloc[:, 1:]\n",
    "    df = df.dropna()\n",
    "    \n",
    "    for col in num_cols:\n",
    "        df[col] = df[col].astype('float')\n",
    "    \n",
    "    df = df[(df.x7 > -10) & (df.x8 < 10)]\n",
    "    \n",
    "    if df.x5.dtype == 'bool':\n",
    "        df.x5 = df.x5.replace({True: 1, False: 0})\n",
    "    if df.x5.dtype == 'O':\n",
    "        df.x5 = df.x5.replace({'True': 1, 'False': 0})\n",
    "    df.x6 = df.x6.replace({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'Fx': 6})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data and extract features and labels\n",
    "all_train_data = data_prepocessing(all_train_data)\n",
    "\n",
    "num_features = all_train_data[num_cols]\n",
    "cat_features = all_train_data[cat_cols]\n",
    "labels = all_train_data.y\n",
    "\n",
    "all_train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of samples in each class\n",
    "classes, cnts = np.unique(labels, return_counts=True)\n",
    "print('classes:\\n  {}'.format(classes))\n",
    "print('samples:\\n  {}'.format(cnts))\n",
    "print('%:\\n  {}'.format(cnts/len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numerical labels\n",
    "labels = labels.replace({'Atsuto': 0, 'Bob': 1, 'JÃ¶rg': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot histogram of features\n",
    "def features_hist(df):\n",
    "    n_bins = 50\n",
    "    for col in num_cols:\n",
    "        ax = plt.subplots(figsize=(6,3))\n",
    "        ax = plt.hist(df[col], bins=n_bins)\n",
    "        title=\"Histogram of \" + col\n",
    "        plt.title(title, fontsize=12)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data to Gaussian-like\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "def feature_transformer(df):\n",
    "    pt = PowerTransformer(standardize=False)\n",
    "    transformed = pd.DataFrame(pt.fit_transform(df))\n",
    "\n",
    "    transformed.columns=df.columns\n",
    "    transformed.index=df.index\n",
    "    \n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot histogram\n",
    "features_hist(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform features\n",
    "num_features_transformed = feature_transformer(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot histogram\n",
    "features_hist(num_features_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlation of features\n",
    "cor = num_features_transformed.corr(method='pearson')\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.heatmap(cor, mask=np.zeros_like(cor, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop redundant features\n",
    "# drop_cols = ['x3']\n",
    "# features_scaled = features_scaled.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split train and test dataset\n",
    "features = pd.concat([num_features_transformed, cat_features], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check numbers of each class\n",
    "classes, cnts = np.unique(y_train, return_counts=True)\n",
    "print('samples in training data:\\n  {}'.format(cnts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def accuracy_calculator(classifier):\n",
    "    pred = classifier.predict(x_test)\n",
    "    accuracy = round(accuracy_score(y_test, pred), 4)\n",
    "    print('test accuracy: {}'.format(accuracy))\n",
    "\n",
    "    lb = np.array(y_test)\n",
    "    acc_per_class = []\n",
    "\n",
    "    for i in range(3):\n",
    "        y_i = pred[lb==i]\n",
    "        acc_per_class.append(round(1 - y_i[y_i!=i].shape[0] / y_i.shape[0], 4))\n",
    "\n",
    "    print('accuracy of classes:\\n  {}'.format(acc_per_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier 1: random forest\n",
    "# use GridSearchCV to tune parameters\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators'      : [100],\n",
    "    'max_depth'         : [None],\n",
    "    'min_samples_split' : [1, 2, 3, 4, 5],\n",
    "    'min_samples_leaf'  : [1, 2, 3, 4, 5],\n",
    "    'random_state'      : [0],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator=rf_clf, param_grid=parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "best_rf = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier 2: extremely randomized tree\n",
    "# use GridSearchCV to tune parameters\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "ef_clf = ExtraTreesClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators'      : [100],\n",
    "    'max_depth'         : [None],\n",
    "    'min_samples_split' : [1, 2, 3, 4, 5],\n",
    "    'min_samples_leaf'  : [1, 2, 3, 4, 5],\n",
    "    'random_state'      : [0],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator=ef_clf, param_grid=parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "best_ef = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier 3: gradient tree boosting\n",
    "# use GridSearchCV to tune parameters\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate'     : [0.1],\n",
    "    'n_estimators'      : [100],\n",
    "    'max_depth'         : [3],\n",
    "    'min_samples_split' : [1, 2, 3],\n",
    "    'min_samples_leaf'  : [1, 2, 3],\n",
    "    'random_state'      : [0],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator=gb_clf, param_grid=parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "best_gb = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply voting classifer with\n",
    "# classifier 1: random forest\n",
    "# classifier 2: extremely randomized tree\n",
    "# classifier 3: gradient tree boosting\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting = VotingClassifier(\n",
    "    estimators=[('rf', best_rf), ('ef', best_ef), ('gb', best_gb)],\n",
    "    voting='soft',\n",
    "    weights=[1, 1, 1],\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "voting.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy of voting\n",
    "# accuracy_calculator(best_rf)\n",
    "# accuracy_calculator(best_ef)\n",
    "# accuracy_calculator(best_gb)\n",
    "accuracy_calculator(voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process evluation data\n",
    "all_evalu_data = pd.read_csv('EvaluateOnMe.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_evalu_data = data_prepocessing(all_evalu_data)\n",
    "all_evalu_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = all_evalu_data[num_cols]\n",
    "cat_data = all_evalu_data[cat_cols]\n",
    "num_data_transformed = feature_transformer(num_data)\n",
    "features_hist(num_data_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([num_data_transformed, cat_data], axis=1)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predictions = voting.predict(data)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels\n",
    "results = []\n",
    "for p in predictions:\n",
    "    if p == 0:\n",
    "        results.append('Atsuto')\n",
    "    if p == 1:\n",
    "        results.append('Bob')\n",
    "    if p == 2:\n",
    "        results.append('JÃ¶rg')\n",
    "        \n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to txt file\n",
    "with open('106716.txt', 'w') as f:\n",
    "    for item in results:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbers in each class\n",
    "classes, cnts = np.unique(results, return_counts=True)\n",
    "print('all classes:\\n  {}'.format(classes))\n",
    "print('counts of classes:\\n  {}'.format(cnts))\n",
    "print('%:\\n  {}'.format(cnts/len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit5179843866d94cf38ac04fcdba709a21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
